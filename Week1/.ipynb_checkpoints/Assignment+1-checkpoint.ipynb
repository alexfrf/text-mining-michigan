{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you'll be working with messy medical data and using regex to extract relevant infromation from the data. \n",
    "\n",
    "Each line of the `dates.txt` file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset and to properly normalize and sort the dates. \n",
    "\n",
    "Here is a list of some of the variants you might encounter in this dataset:\n",
    "* 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "* Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009;\n",
    "* 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "* Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "* Feb 2009; Sep 2009; Oct 2010\n",
    "* 6/2008; 12/2009\n",
    "* 2009; 2010\n",
    "\n",
    "Once you have extracted these date patterns from the text, the next step is to sort them in ascending chronological order accoring to the following rules:\n",
    "* Assume all dates in xx/xx/xx format are mm/dd/yy\n",
    "* Assume all dates where year is encoded in only two digits are years from the 1900's (e.g. 1/5/89 is January 5th, 1989)\n",
    "* If the day is missing (e.g. 9/2009), assume it is the first day of the month (e.g. September 1, 2009).\n",
    "* If the month is missing (e.g. 2010), assume it is the first of January of that year (e.g. January 1, 2010).\n",
    "* Watch out for potential typos as this is a raw, real-life derived dataset.\n",
    "\n",
    "With these rules in mind, find the correct date in each note and return a pandas Series in chronological order of the original Series' indices.\n",
    "\n",
    "For example if the original series was this:\n",
    "\n",
    "    0    1999\n",
    "    1    2010\n",
    "    2    1978\n",
    "    3    2015\n",
    "    4    1985\n",
    "\n",
    "Your function should return this:\n",
    "\n",
    "    0    2\n",
    "    1    4\n",
    "    2    0\n",
    "    3    1\n",
    "    4    3\n",
    "\n",
    "Your score will be calculated using [Kendall's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), a correlation measure for ordinal data.\n",
    "\n",
    "*This function should return a Series of length 500 and dtype int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         03/25/93 Total time of visit (in minutes):\\n\n",
       "1                       6/18/85 Primary Care Doctor:\\n\n",
       "2    sshe plans to move as of 7/8/71 In-Home Servic...\n",
       "3                7 on 9/27/75 Audit C Score Current:\\n\n",
       "4    2/6/96 sleep studyPain Treatment Pain Level (N...\n",
       "5                    .Per 7/06/79 Movement D/O note:\\n\n",
       "6    4, 5/18/78 Patient's thoughts about current su...\n",
       "7    10/24/89 CPT Code: 90801 - Psychiatric Diagnos...\n",
       "8                         3/7/86 SOS-10 Total Score:\\n\n",
       "9             (4/10/71)Score-1Audit C Score Current:\\n\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "doc = []\n",
    "with open('dates.txt') as file:\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "\n",
    "df = pd.Series(doc)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleex\\AppData\\Local\\Temp/ipykernel_24736/772952018.py:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = df1.append(df2[~df2.level_0.isin(df1.level_0)]) # df1 añade las filas de df2 cuyo level_0 no exista en df1\n",
      "C:\\Users\\aleex\\AppData\\Local\\Temp/ipykernel_24736/772952018.py:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append(df3[~df3.level_0.isin(output.level_0)]) # df1+df2 añade las filas de df3 cuyo level_0 no exista en df1+df2\n",
      "C:\\Users\\aleex\\AppData\\Local\\Temp/ipykernel_24736/772952018.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append(df4[~df4.level_0.isin(output.level_0)]) # df1+df2+df3 añade las filas de df4 cuyo level_0 no exista en df1+df2+df3\n",
      "C:\\Users\\aleex\\AppData\\Local\\Temp/ipykernel_24736/772952018.py:55: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output = output.append(df5[~df5.level_0.isin(output.level_0)]) # df1+df2+df3+df4 añade las filas de df5 cuyo level_0 no exista en df1+df2+df3+df4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0        9\n",
       " 1       84\n",
       " 2        2\n",
       " 3       53\n",
       " 4       28\n",
       "       ... \n",
       " 495    427\n",
       " 496    141\n",
       " 497    186\n",
       " 498    161\n",
       " 499    413\n",
       " Name: level_0, Length: 500, dtype: int64,\n",
       " 0     1971-04-10\n",
       " 1     1971-05-18\n",
       " 2     1971-07-08\n",
       " 3     1971-07-11\n",
       " 4     1971-09-12\n",
       "          ...    \n",
       " 495   2016-05-01\n",
       " 496   2016-05-30\n",
       " 497   2016-10-13\n",
       " 498   2016-10-19\n",
       " 499   2016-11-01\n",
       " Name: date, Length: 500, dtype: datetime64[ns])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def date_sorter():\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "\n",
    "    dates = [\"•04/20/2009;\", \"04/20/09;\", \"4/20/09;\", \"4/3/09;\",\n",
    "    \"•Mar-20-2009;\", \"Mar 20, 2009;\", \"March 20, 2009;\", \"Mar. 20, 2009;\", \"Mar 20 2009;\", \"October 14 1974\",\n",
    "    \"•20 Mar 2009;\", \"20 March 2009;\", \"20 Mar. 2009;\", \"20 March, 2009\",\"2June, 1999\",\n",
    "    \"•Mar 20th, 2009;\", \"Mar 21st, 2009;\", \"Mar 22nd, 2009\",\n",
    "    \"•Feb 2009;\", \"Sep 2009;\", \"Oct 2010\",\n",
    "    \"•6/2008;\", \"12/2009\",\n",
    "    \"•2009;\", \"2010\"] # rango con la tipología de las fechas existentes en el .txt\n",
    "\n",
    "    dates = pd.Series(dates)\n",
    "    \n",
    "    # \"•04/20/2009;\", \"04/20/09;\", \"4/20/09;\", \"4/3/09;\"\n",
    "    rule_1 = r'(0?\\d|1[0-2])[\\/\\-](0?\\d|[12]\\d|30|31)[\\/\\-](\\d{4}|\\d{2})'\n",
    "    df1 = df.str.extractall(rule_1) # con .extractall hacemos un df con todas las líneas del .txt con una tipología de fecha = rule_1\n",
    "    df1.columns = ['month','day','year'] # adecuada para la tipología que estamos tratando\n",
    "    df1=df1.reset_index()\n",
    "    \n",
    "    \n",
    "    # \"•Mar-20-2009;\", \"Mar 20, 2009;\", \"March 20, 2009;\", \"Mar. 20, 2009;\", \"Mar 20 2009;\", \"October 14 1974\",\n",
    "    # Mar 20th, 2009;\", \"Mar 21st, 2009;\", \"Mar 22nd, 2009\"\n",
    "    rule_2 = r'(Jan|Feb|Mar|Apr|May|Jun|Jul|Ago|Sep|Oct|Nov|Dec)[a-z\\.]*[ -](\\d{1,2})[a-z\\.\\,]*[ -](\\d{4})'\n",
    "    df2= df.str.extractall(rule_2)\n",
    "    df2.columns = ['month','day','year']\n",
    "    df2 = df2.reset_index()\n",
    "    \n",
    "    # \"•20 Mar 2009;\", \"20 March 2009;\", \"20 Mar. 2009;\", \"20 March, 2009\",\"2June, 1999\"\n",
    "    # \"•Feb 2009;\", \"Sep 2009;\", \"Oct 2010\"\n",
    "    rule_3 = r'(\\d{1,2})?[ -]?(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z\\.\\,]*[ -](\\d{4})'\n",
    "    df3= df.str.extractall(rule_3)\n",
    "    df3.columns = ['day','month','year']\n",
    "    df3 = df3.reset_index()\n",
    "    \n",
    "    # \"•6/2008;\", \"12/2009\",\n",
    "    rule_4 =r'(\\d{1,2})[/](\\d{4})'\n",
    "    df4 = df.str.extractall(rule_4)\n",
    "    df4.insert(0,column='day',value=np.nan) # al no tener días, tenemos que crear una columna de 0 (o de NaN) para respetar el formato\n",
    "    df4.columns = ['day','month','year']\n",
    "    df4 = df4.reset_index()\n",
    "    \n",
    "    rule_5 = r'(\\d{4})'\n",
    "    df5 = df.str.extractall(rule_5)\n",
    "    df5.insert(0, column='day', value=np.nan) #al no tener días, tenemos que crear una columna de 0 (o de NaN) para respetar el formato\n",
    "    df5.insert(1, column='month', value=np.nan) # al no tener meses, tenemos que crear una columna de 0 (o de NaN) para respetar el formato\n",
    "    df5.columns = [\"month\", \"day\", \"year\"]\n",
    "    df5=df5.reset_index()\n",
    "    \n",
    "    output = df1.append(df2[~df2.level_0.isin(df1.level_0)]) # df1 añade las filas de df2 cuyo level_0 no exista en df1\n",
    "    output = output.append(df3[~df3.level_0.isin(output.level_0)]) # df1+df2 añade las filas de df3 cuyo level_0 no exista en df1+df2\n",
    "    output = output.append(df4[~df4.level_0.isin(output.level_0)]) # df1+df2+df3 añade las filas de df4 cuyo level_0 no exista en df1+df2+df3\n",
    "    output = output.append(df5[~df5.level_0.isin(output.level_0)]) # df1+df2+df3+df4 añade las filas de df5 cuyo level_0 no exista en df1+df2+df3+df4\n",
    "    \n",
    "    output = pd.DataFrame(output,columns = [\"level_0\", \"match\", \"day\", \"month\",\"year\"]) # reconfiguramos el df de output\n",
    "    output['year'] = np.where(output.year.apply(len)==2,\"19\"+output.year,output.year) # reformateamos la columna año, adecuando los 2 digitos a 4 digitos\n",
    "    output = output.fillna(\"1\") # y añadimos un 1 a los NaN. Así, cuando no haya ni día ni mes será 1 de enero\n",
    "    \n",
    "    # Falta formatear los meses. Cambiar Enero, febrero, etc, por números\n",
    "    \n",
    "    rang = []\n",
    "    for i in range(1,13):\n",
    "        rang.append(i)\n",
    "\n",
    "    ranges = dict(zip(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'],rang))\n",
    "    \n",
    "    output.month = output.month.replace(ranges) # reemplazamos cada mes por su ordinal\n",
    "    \n",
    "    #Transformamos todas las filas de str a int para poder ordenar\n",
    "    output['month'] = output.month.astype(int)\n",
    "    output['day'] = output.day.astype(int)\n",
    "    output['year'] = output.year.astype(int)\n",
    "    \n",
    "    # Y creamos una columna formato datetime para cada fila\n",
    "    \n",
    "    output[\"date\"] = pd.to_datetime(output.loc[:,[\"year\", \"month\", \"day\"]])\n",
    "    output = output.sort_values([\"date\", \"level_0\"]).reset_index(drop=True) # Ordenamos por fecha\n",
    "    \n",
    "    \n",
    "    return output.level_0,output.date\n",
    "\n",
    "date_sorter()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
